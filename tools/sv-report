#!/usr/bin/env python3

from pygments.formatters import HtmlFormatter
from pygments import lexers, highlight
import multiprocessing
from glob import glob
from logparser import parseLog
import argparse
import logging
import jinja2
import csv
import sys
import os
import re

parser = argparse.ArgumentParser()

logger_args = parser.add_mutually_exclusive_group()

logger_args.add_argument(
    "-q", "--quiet", action="store_true", help="Disable all logs")

logger_args.add_argument(
    "-v", "--verbose", action="store_true", help="Verbose logging")

parser.add_argument(
    "-i", "--input", help="Input database/LRM", default="conf/lrm.conf")

parser.add_argument(
    "-l",
    "--logs",
    help="Directory with all the individual test results",
    default="out/logs")

parser.add_argument(
    "--template",
    help="Path to the html report template",
    default="conf/report/report-template.html")

parser.add_argument(
    "--code-template",
    help="Path to the html code preview template",
    default="conf/report/code-template.html")

parser.add_argument(
    "--log-template",
    help="Path to the html log template",
    default="conf/report/log-template.html")

parser.add_argument(
    "-o",
    "--out",
    help="Path to the html file with the report",
    default="out/report/index.html")

parser.add_argument(
    "-c",
    "--csv",
    help="Path to the csv file with the report",
    default="out/report/report.csv")

parser.add_argument(
    "-r", "--revision", help="Report revision", default="unknown")

# parse args
args = parser.parse_args()

# setup logger
logger = logging.getLogger()
logger.setLevel(logging.DEBUG)

ch = logging.StreamHandler()
ch.setFormatter(logging.Formatter('%(levelname)-8s| %(message)s'))
logger.addHandler(ch)

if args.quiet:
    logger.setLevel(logging.ERROR)
elif args.verbose:
    logger.setLevel(logging.DEBUG)
else:
    logger.setLevel(logging.INFO)

tag_usage = {}

lex = lexers.get_lexer_by_name("systemverilog")

# Initialize templates
with open(args.code_template, "r") as templ:
    src_template = jinja2.Template(
        templ.read(), trim_blocks=True, lstrip_blocks=True)

with open(args.log_template, "r") as templ:
    log_template = jinja2.Template(
        templ.read(), trim_blocks=True, lstrip_blocks=True)


def exists_and_is_newer_than(b, a):
    return os.path.exists(b) and os.path.getctime(b) > os.path.getctime(a)


def formatSrc(ifile, ofile):
    if exists_and_is_newer_than(ofile, ifile):
        return

    formatter = HtmlFormatter(
        full=False, linenos=True, anchorlinenos=True, lineanchors='l')
    with open(ifile, 'rb') as f:
        raw_code = f.read()
        os.makedirs(os.path.dirname(ofile), exist_ok=True)

        code = highlight(raw_code, lex, formatter)

        with open(ofile, 'w') as out:
            filename = os.path.relpath(ifile)
            src_rel = "../" * filename.count('/')
            csspath = os.path.join(src_rel, "code.css")

            out.write(
                src_template.render(
                    csspath=csspath, filename=filename, code=code))


def fileRefToLink(src_rel, fname, link_pat, link_sub_pat, log):
    f_rel = os.path.relpath(fname)
    f_html = (
        '<a href="{0}{1}.html" target="file-frame">{1}</a>'.format(
            src_rel, f_rel))
    log = re.sub(
        link_pat.format(fname), link_sub_pat.format(src_rel, f_rel), log)
    log = re.sub(fname, f_html, log)
    formatSrc(fname, os.path.join(os.path.dirname(args.out), f_rel + '.html'))
    return (f_html, log)


def logToHTML(path_in, path_out, tags):
    depth = path_in.count('/') - 1
    src_relative = '../' * depth
    files = tags['files'].split()
    log = str(jinja2.escape(tags['log']))
    log_files_pat = r'({}\S+):\d+'
    html_pat_ln = r'{}:(\d+)'
    html_sub_ln = r'<a href="{0}{1}.html#l-\1" target="file-frame">{1}:\1</a>'

    tags['tool'] = "toolname"
    tags['tool_url'] = "toolname.pl"

    tags['file_urls'] = []

    log_files = re.findall(log_files_pat.format(os.getcwd()), log)

    log_files = list(set(log_files) - set(files))

    for f in log_files:
        if os.path.isfile(f):
            _, log = fileRefToLink(
                src_relative, f, html_pat_ln, html_sub_ln, log)

    for f in files:
        url, log = fileRefToLink(
            src_relative, f, html_pat_ln, html_sub_ln, log)
        tags['file_urls'].append(url)

    tags['file_urls'] = " ".join(tags['file_urls'])
    tags['log_urls'] = log

    with open(path_out + ".html", 'w') as html:
        html.write(log_template.render(**tags))

    return os.path.relpath(files[0]) + '.html'


def getRelativePaths(paths):
    paths = paths.split(' ')
    paths = list(map(lambda x: os.path.realpath(x), paths))

    return ' '.join(paths)


# class used for sorting "test tabs" in the report
class TestTupleComp(object):
    def __init__(self, item):
        self.item = item

    def prepend_nums(self, s):
        # prepend all number occurences with the length of the number
        for m in re.findall(r'\d+', s):
            s = s.replace(m, str(len(m)) + m)

        return s

    def __lt__(self, other):
        s = self.prepend_nums(self.item[1]["name"])
        o = self.prepend_nums(other.item[1]["name"])

        return s < o


# generate input database first
database = {}
try:
    with open(args.input) as f:
        for l in f:
            ls = l.strip()
            # skip lines with comments
            if re.search(r"^\s*#.*", ls) is not None:
                continue

            entry = ls.split("\t")

            if len(entry) < 2:
                raise KeyError("Invalid entry: " + ls)

            database[entry[0]] = "\t".join(entry[1:])
except KeyError as e:
    # TODO: exit on error/critical handler
    logger.critical("Unable to parse the database - " + str(e))
    sys.exit(1)

logger.info("Generating {} from log files in '{}'".format(args.out, args.logs))

data = {}

for tag in database:
    tag_usage[tag] = False


def collect_logs(runner_name):
    runner_data = {}
    runner_tag_usage = {}

    for tag in database:
        runner_tag_usage[tag] = False

    # all tests info
    runner_data["tests"] = {}
    tests = runner_data["tests"]
    runner_data["time_elapsed"] = 0

    for t in glob(os.path.join(args.logs, runner_name, "**/*.log"),
                  recursive=True):
        t_id = t[len(args.logs) + 1:]
        logger.debug("Found log: " + t_id)

        tests[t_id] = {}

        test_tags = [
            "name", "tags", "should_fail", "rc", "description", "files",
            "incdirs", "top_module", "runner", "runner_url", "time_elapsed",
            "timeout", "type", "mode"
        ]
        with open(t, "r") as f:
            try:
                for l in f:
                    tag = re.search(r"^([a-zA-Z_-]+):(.+)", l)

                    if tag is None:
                        raise KeyError(
                            "Could not find tags: {}".format(
                                ", ".join(test_tags)))

                    param = tag.group(1).lower()
                    value = tag.group(2).strip()

                    if param in test_tags:
                        test_tags.remove(param)
                        tests[t_id][param] = value

                        if len(test_tags) == 0:
                            # found all tags
                            break
                    else:
                        logger.warning(
                            "Skipping unknown parameter: {} in {}".format(
                                param, t))

            except Exception as e:
                logger.warning(
                    "Skipping {} on {}: {}".format(t, runner_name, str(e)))
                del tests[t_id]
                continue

            tests[t_id]["log"] = f.read()
            tests[t_id]["fname"] = os.path.join('logs', t_id + '.html')

            tool_should_fail = tests[t_id]["should_fail"] == "1"
            tool_rc = int(tests[t_id]["rc"])
            tool_failed = (tool_rc != 0)
            if tool_rc >= 126 or tool_should_fail != tool_failed:
                tests[t_id]["status"] = "test-failed"
            elif tests[t_id]["mode"] == 'simulation' and not parseLog(
                    tests[t_id]["log"]):
                tests[t_id]["status"] = "test-failed"
            else:
                tests[t_id]["status"] = "test-passed"

            t_html = t.replace(
                args.logs, os.path.join(os.path.dirname(args.out), "logs"))
            os.makedirs(os.path.dirname(t_html), exist_ok=True)

            tests[t_id]["first_file"] = logToHTML(t, t_html, tests[t_id])

            runner_data["time_elapsed"] += float(tests[t_id]["time_elapsed"])

        # check if test was skipped
        if t_id not in tests:
            continue

        # Initialize the tag-based side of the result dict
        runner_data["tags"] = {}
        tags = runner_data["tags"]

        for tag in database:
            tags[tag] = {}
            tags[tag]["status"] = []

        # generate tags summary
        for _, test in tests.items():
            for tag in test["tags"].split(" "):
                try:
                    runner_tag_usage[tag] = True
                    tags[tag]["status"].append(test["status"])
                except KeyError:
                    logger.warning("Tag not present in the database: " + tag)
                    database[tag] = ''
                    runner_tag_usage[tag] = True
                    tags[tag] = {}
                    tags[tag]["status"] = test["status"]
                    continue

        for tag in tags:
            tags[tag]["passed-num"] = tags[tag]["status"].count("test-passed")

            if len(tags[tag]["status"]) == 0:
                tags[tag]["status"] = "test-na"
            elif all(tags[tag]["status"][0] == x for x in tags[tag]["status"]):
                tags[tag]["status"] = tags[tag]["status"][0]
            else:
                tags[tag]["status"] = "test-varied"
    return (runner_data, runner_tag_usage)


pool = multiprocessing.Pool()
runner_names = []

for r in [os.path.dirname(r) for r in glob(args.logs + "/*/")]:
    runner_name = os.path.basename(r)
    logger.debug("Found Runner: " + runner_name)

    runner_names.append(runner_name)

results = pool.map(collect_logs, runner_names)

for r, d in zip(runner_names, results):
    data[r] = d[0]
    for tag in d[1]:
        if not tag in database:
            database[tag] = ''
        if not tag_usage.get(tag, False):
            tag_usage[tag] = d[1][tag]

pool.close()

for tag in tag_usage:
    if not tag_usage[tag]:
        del database[tag]

csv_header = ['name', 'files', 'tags']
csv_output = {}
duplicates = []

for r in data:
    csv_header.append(r)
    for test in data[r]["tests"]:
        test_handle = data[r]["tests"][test]
        name = test_handle["name"]
        files = getRelativePaths(test_handle["files"])

        try:
            if csv_output[name]["files"] != files:
                logger.error(
                    "Duplicate test: {}, first use: {}, second: {}".format(
                        name, csv_output[name]["files"], files))
                if name not in duplicates:
                    duplicates.append(name)
            else:
                csv_output[name][r] = test_handle["status"] == "test-passed"
        except KeyError:
            csv_output[name] = {}
            csv_output[name]["name"] = test_handle["name"]
            csv_output[name]["files"] = files
            csv_output[name]["tags"] = test_handle["tags"]
            csv_output[name][r] = test_handle["status"] == "test-passed"

if len(duplicates) > 0:
    logger.critical("Unable to generate report, duplicate test names")
    sys.exit(1)

try:
    for r in data:
        with open(os.path.join(args.logs, r, "version")) as version_file:
            data[r]["version"] = version_file.read()

        for tag in data[r]["tags"]:
            tag_handle = data[r]["tags"][tag]

            tag_handle["logs"] = {}

            for test in data[r]["tests"]:
                test_handle = data[r]["tests"][test]
                if tag in test_handle["tags"].split():
                    tag_handle["logs"][test] = {}
                    inner = tag_handle["logs"][test]
                    inner["log"] = test_handle["log"].replace("\n", "</br>")
                    inner["status"] = test_handle["status"]
                    inner["name"] = test_handle["name"]
                    inner["fname"] = test_handle["fname"]
                    inner["first_file"] = test_handle["first_file"]

            # sort logs
            tag_handle["logs_sorted"] = sorted(
                tag_handle["logs"].items(), key=TestTupleComp)
            if len(tag_handle["logs_sorted"]) > 0:
                tag_handle["head_test"] = tag_handle["logs_sorted"][0][0]

        data[r]["total"] = {}

        # find the number of tests that passed
        rts = data[r]["tests"]
        data[r]["total"]["tests"] = sum(
            1 for t in rts if rts[t]["status"] in "test-passed")

        # find the number of tags for which all the tests passed
        rtt = data[r]["tags"]
        data[r]["total"]["tags"] = sum(
            1 for t in rtt if rtt[t]["status"] in "test-passed")

    with open(args.template, "r") as f:
        report = jinja2.Template(
            f.read(), trim_blocks=True, lstrip_blocks=True)

    with open(args.out, 'w') as f:
        f.write(
            report.render(
                report=data, database=database, revision=args.revision))

    with open(args.csv, 'w', newline='') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=csv_header)
        writer.writeheader()
        for test in csv_output:
            writer.writerow(csv_output[test])
except KeyError:
    logger.critical("Unable to generate report, not enough logs")
except Exception as e:
    logger.critical("Unable to generate report: " + str(e))
